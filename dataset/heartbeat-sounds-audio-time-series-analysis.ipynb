{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857c369f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-17T14:15:23.252066Z",
     "iopub.status.busy": "2021-11-17T14:15:23.251370Z",
     "iopub.status.idle": "2021-11-17T14:15:25.717714Z",
     "shell.execute_reply": "2021-11-17T14:15:25.718281Z",
     "shell.execute_reply.started": "2021-11-17T13:54:27.963812Z"
    },
    "papermill": {
     "duration": 2.495301,
     "end_time": "2021-11-17T14:15:25.718613",
     "exception": false,
     "start_time": "2021-11-17T14:15:23.223312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For audio files \n",
    "import librosa as lr\n",
    "from glob import glob\n",
    "\n",
    "# Lineas algebra\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data laoding\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a9e803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:15:25.760853Z",
     "iopub.status.busy": "2021-11-17T14:15:25.760151Z",
     "iopub.status.idle": "2021-11-17T14:15:25.876326Z",
     "shell.execute_reply": "2021-11-17T14:15:25.875693Z",
     "shell.execute_reply.started": "2021-11-17T13:57:17.261702Z"
    },
    "papermill": {
     "duration": 0.139178,
     "end_time": "2021-11-17T14:15:25.876473",
     "exception": false,
     "start_time": "2021-11-17T14:15:25.737295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default settings\n",
    "plt.rcParams['figure.dpi'] = 200 #high resolution\n",
    "colors = ['#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51']\n",
    "colors.reverse()\n",
    "colors = sns.color_palette(colors)\n",
    "sns.palplot(colors)\n",
    "sns.set_palette(colors)\n",
    "\n",
    "# utilities\n",
    "def get_unique_count(col):\n",
    "    return setA_df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c54f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:15:25.918103Z",
     "iopub.status.busy": "2021-11-17T14:15:25.917422Z",
     "iopub.status.idle": "2021-11-17T14:15:27.325693Z",
     "shell.execute_reply": "2021-11-17T14:15:27.324720Z",
     "shell.execute_reply.started": "2021-11-17T14:02:47.441051Z"
    },
    "papermill": {
     "duration": 1.430158,
     "end_time": "2021-11-17T14:15:27.325994",
     "exception": true,
     "start_time": "2021-11-17T14:15:25.895836",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sfreq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/4288151655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read one audio file, create the time array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_sfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msfreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sfreq' is not defined"
     ]
    }
   ],
   "source": [
    "# List all the wave files in the folder\n",
    "data_dir = '../input/heartbeat-sounds/set_a'\n",
    "audio_files = glob(data_dir + '/*.wav')\n",
    "\n",
    "# Read one audio file, create the time array\n",
    "audio, audio_sfreq = lr.load(audio_files[20])\n",
    "time = np.arange(0, len(audio)) / sfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c396ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Exploring the data\n",
    "Each audio file shows the sound amplitude of a person's heartbeat thruogh time. This is a special kind of time series since it shows data from every second of the heartbeat. This data is important for diagnosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9de752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:02:50.520217Z",
     "iopub.status.busy": "2021-11-17T14:02:50.519919Z",
     "iopub.status.idle": "2021-11-17T14:02:50.818226Z",
     "shell.execute_reply": "2021-11-17T14:02:50.817336Z",
     "shell.execute_reply.started": "2021-11-17T14:02:50.520185Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot audio over time\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, audio)\n",
    "ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n",
    "ax.set_title('Heartbeat of person through time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e53537",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Normal vs Abnormal\n",
    "How does the data differ in an abnormal patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c4bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:01:01.061212Z",
     "iopub.status.busy": "2021-11-17T14:01:01.060944Z",
     "iopub.status.idle": "2021-11-17T14:01:01.097209Z",
     "shell.execute_reply": "2021-11-17T14:01:01.096636Z",
     "shell.execute_reply.started": "2021-11-17T14:01:01.061184Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "setA_df = pd.read_csv('../input/heartbeat-sounds/set_a.csv')\n",
    "setA_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d348b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:01:10.241612Z",
     "iopub.status.busy": "2021-11-17T14:01:10.241297Z",
     "iopub.status.idle": "2021-11-17T14:01:10.251520Z",
     "shell.execute_reply": "2021-11-17T14:01:10.250780Z",
     "shell.execute_reply.started": "2021-11-17T14:01:10.241563Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels in the data \n",
    "set(setA_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7796b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:02:58.884906Z",
     "iopub.status.busy": "2021-11-17T14:02:58.884364Z",
     "iopub.status.idle": "2021-11-17T14:03:00.067707Z",
     "shell.execute_reply": "2021-11-17T14:03:00.066388Z",
     "shell.execute_reply.started": "2021-11-17T14:02:58.884871Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting the normal and abnormal heartbeat sounds\n",
    "normal = audio_files = glob(data_dir + '/normal__2011*.wav')\n",
    "abnormal = audio_files = glob(data_dir + '/murmur*.wav')\n",
    "\n",
    "# The lengths are the same \n",
    "#assert len(normal) == len(abnormal)\n",
    "\n",
    "# Calculate the time array \n",
    "time = np.arange(0, len(normal)) / sfreq\n",
    "\n",
    "# Read one audio file, create the time array\n",
    "normal_audio, sfreq = lr.load(normal[0])\n",
    "abnormal_audio, sfreq = lr.load(abnormal[0])\n",
    "\n",
    "# Calculate the time array \n",
    "time = np.arange(0, len(normal_audio)) / sfreq\n",
    "\n",
    "# Visualize the data \n",
    "fig2, ax2 = plt.subplots(2,1)\n",
    "ax2[0].plot(time, normal_audio)\n",
    "ax2[0].set_xlabel('time')\n",
    "ax2[0].set_ylabel('heartbeat')\n",
    "ax2[0].set_title('normal')\n",
    "ax2[1].plot(time, abnormal_audio)\n",
    "ax2[1].set_xlabel('time')\n",
    "ax2[1].set_ylabel('heartbeat')\n",
    "ax2[1].set_title('abnormal')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6e210",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# The auditory envelope\n",
    "\n",
    "Smoothing the data helps us calculate the auditory envelope related to the total amount of audio energy present at each moment of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928aa443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:03:54.945052Z",
     "iopub.status.busy": "2021-11-17T14:03:54.944779Z",
     "iopub.status.idle": "2021-11-17T14:03:55.310219Z",
     "shell.execute_reply": "2021-11-17T14:03:55.309606Z",
     "shell.execute_reply.started": "2021-11-17T14:03:54.945024Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a series of data points \n",
    "audio = pd.Series(normal_audio, index=time)\n",
    "\n",
    "# Plot the raw data first\n",
    "raw_plot = audio.plot(figsize=(10, 5))\n",
    "raw_plot.set_title('Raw data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33d76f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Rectifying the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fba5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:04:16.541823Z",
     "iopub.status.busy": "2021-11-17T14:04:16.541513Z",
     "iopub.status.idle": "2021-11-17T14:04:16.927589Z",
     "shell.execute_reply": "2021-11-17T14:04:16.926960Z",
     "shell.execute_reply.started": "2021-11-17T14:04:16.541789Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rectify the audio signal\n",
    "audio_rectified = audio.apply(np.abs)\n",
    "\n",
    "# Plot the result\n",
    "rectified_plot = audio_rectified.plot(figsize=(10, 5))\n",
    "rectified_plot.set_title('Rectified audio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d457d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Smoothening the data and removing the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8efd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:04:42.181104Z",
     "iopub.status.busy": "2021-11-17T14:04:42.180553Z",
     "iopub.status.idle": "2021-11-17T14:04:42.526094Z",
     "shell.execute_reply": "2021-11-17T14:04:42.525478Z",
     "shell.execute_reply.started": "2021-11-17T14:04:42.181068Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smooth by applying a rolling mean\n",
    "audio_rectified_smooth = audio_rectified.rolling(50).mean()\n",
    "\n",
    "# Plot the result\n",
    "audio_rectified_smooth.plot(figsize=(10, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4bd04a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "By rectifying the signal and cleaning up all the noise, we now have a better understanding of the data and can draw insights from itðŸ™‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e82f1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Derivative features: The tempogram \n",
    "Auditory data has a set of features that can help us extract valuable data from it. We can get the tempogram of an audio to compute the rythm and tempo of it.\n",
    "These features can help us and the model get a better sense of the data we're dealing with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a564d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:08:27.306160Z",
     "iopub.status.busy": "2021-11-17T14:08:27.305771Z",
     "iopub.status.idle": "2021-11-17T14:08:27.319144Z",
     "shell.execute_reply": "2021-11-17T14:08:27.318617Z",
     "shell.execute_reply.started": "2021-11-17T14:08:27.306130Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal_series = pd.Series(normal_audio, time)\n",
    "abnormal_series = pd.Series(abnormal_audio, time)\n",
    "audio_df = pd.concat([normal_series, abnormal_series], axis=1)\n",
    "\n",
    "audio_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eee892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:08:35.399287Z",
     "iopub.status.busy": "2021-11-17T14:08:35.398859Z",
     "iopub.status.idle": "2021-11-17T14:08:38.890843Z",
     "shell.execute_reply": "2021-11-17T14:08:38.889892Z",
     "shell.execute_reply.started": "2021-11-17T14:08:35.399253Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_tempo = lr.beat.tempo(normal_audio, sr=sfreq, hop_length=2**6, aggregate=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511edde",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Spectograms\n",
    "In the field of audio engineering, spectograms are used to describe the presense spectral content (low pitch etc.) over time. Spectral analysis is commen in other forms of time series as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5fcad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-17T14:10:38.549604Z",
     "iopub.status.busy": "2021-11-17T14:10:38.548781Z",
     "iopub.status.idle": "2021-11-17T14:10:40.126337Z",
     "shell.execute_reply": "2021-11-17T14:10:40.125343Z",
     "shell.execute_reply.started": "2021-11-17T14:10:38.549523Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the stft function\n",
    "from librosa.core import stft\n",
    "from librosa.core import amplitude_to_db\n",
    "from librosa.display import specshow\n",
    "\n",
    "# Prepare the STFT\n",
    "HOP_LENGTH = 2**4\n",
    "spec = stft(normal_audio, hop_length=HOP_LENGTH, n_fft=2**7)\n",
    "\n",
    "# Convert into decibels\n",
    "spec_db = amplitude_to_db(np.abs(spec))\n",
    "\n",
    "# Compare the raw audio to the spectrogram of the audio\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(time, normal_audio)\n",
    "specshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a08ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can see that heartbeat sounds come in pairs. This is proven by the biology literature. The heart has two sounds in total one in R and the other in the near end of T wave in the elctrogram. \n",
    "\n",
    "![ECG](https://meetjegezondheid.nl/wp-content/uploads/2020/09/normaal-ecg-hartslag.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.436498,
   "end_time": "2021-11-17T14:15:28.254650",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-17T14:15:13.818152",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
